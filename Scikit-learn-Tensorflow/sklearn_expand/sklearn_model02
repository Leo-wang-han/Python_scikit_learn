二、逻辑回归
	2.1 简介
		在“线性回归”模块中，您探索了如何构建模型来进行连续的数值预测，例如汽车的燃油效率。
		但是，如果您想构建一个模型来回答“今天会下雨吗？”或“这封电子邮件是垃圾邮件吗？”这类问题，该怎么办？
		
		逻辑回归作为回归模型，该模型旨在预测给定结果的概率。
		线性回归--数值预测
		逻辑回归--概率预测
		
	2.2 计算概率
	2.2.1 逻辑回归：使用S性函数计算概率
		许多问题需要将概率估算值作为输出。 逻辑回归是 一种极其高效的概率计算机制。
		实际上，您可以通过以下两种方式使用返回的概率：
			“按原样”应用。例如，如果垃圾邮件预测模型将电子邮件视为 输入并输出值 0.932，这表示概率为 93.2% 电子邮件是垃圾邮件。
			转换为二元类别，例如 True 或 False、Spam 或 Not Spam。
			
		2.2.2 S型函数
		您可能想知道逻辑回归模型如何确保其输出表示概率，始终输出介于 0 到 1 之间的值。
		由于 会发生一系列函数，这些函数称为逻辑函数 其输出具有相同的特征。
		标准逻辑函数，也称S型函数（sigmod表示“s"形）：f(x) = 1/(1+ e**-x)
		曲线接近 0 因为 x 值减少到负无穷大，而 1 则等于 x 值越接近无穷大。
		随着输入 x 的增加，sigmoid 函数的输出会接近 1，但永远不会达到 1。
		同样，当输入值减小时，S 型函数值 函数的输出接近，但永远不会达到 0。
		z = b + w1*x1 + w2*x1 + ... + wn*xn
		z作为线性方程的输出（对数几率）
		y' = 1/(1+e**-z)
	
	2.2.2 逻辑回归：损失和正则化
		逻辑回归 模型的训练过程与 线性回归 两个关键区别：
		逻辑回归模型使用 对数损失函数（sigmod）作为损失函数 而不是平方损失函数(MSE)。
		应用正则化 是防止 过拟合。
	
	2.2.3 过拟合：L1，L2正则化
		L1正则化（Lasso正则化）：
			L1正则化在损失函数中添加模型权重的绝对值之和最为惩罚项
				损失函数=原始损失函数 + λ∑∣wi∣
			
		L2正则化（Ridge正则化）：
			L2 正则化在损失函数中添加模型权重的平方和作为惩罚项。
				损失函数=原始损失函数 + λ∑wi**2
​
			wi：模型的权重。
			λ：正则化强度（超参数）。
			
		权重分布
		L1 正则化：倾向于产生稀疏权重，部分权重为 0。
		L2 正则化：倾向于让权重值接近 0，但不为 0。

		优化目标
		L1 正则化：损失函数 + 权重的绝对值之和。
		L2 正则化：损失函数 + 权重的平方和。

		适用场景
		L1 正则化：适用于特征选择和高维数据。
		L2 正则化：适用于防止过拟合和一般性模型优化。
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		